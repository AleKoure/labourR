% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/tf_idf.R
\name{tf_idf}
\alias{tf_idf}
\title{Term frequency–Inverse document frequency}
\usage{
tf_idf(
  corpus,
  stopwords = NULL,
  id_col = "id",
  text_col = "text",
  tf_weight = "double_norm",
  idf_weight = "idf_smooth",
  min_chars = 2
)
}
\arguments{
\item{corpus}{input data, with an id column and a text column. Can be a data.frame or a data.table.}

\item{stopwords}{character vector of stopwords. Stopwords are filtered out before calculating numerical statistics.}

\item{id_col}{input data column name with the ids of the documents.}

\item{text_col}{input data column name with the documents.}

\item{tf_weight}{weighting scheme of term frequency. Choices are `raw_count`, `double_norm` or `log_norm` for raw count, double normalization at 0.5 and log normalization respectively.}

\item{idf_weight}{weighting scheme of inverse document frequency. Choices are `idf` and `idf_smooth` for inverse document frequency and inverse document frequency smooth respectively.}

\item{min_chars}{words with less characters than `min_chars` are filtered out before calculating numerical statistics.}
}
\value{
A data.table with three columns, namely `class` derived from given document ids, `term` and `tfIdf`.
}
\description{
Measure weighted amount of information conserning the specificity of terms in a corpus.
Term frequency–Inverse document frequency is one of the most frequently applied weighting schemes in information retrieval systems.
The tf–idf is a statistical measure proprtional to the number of times a word appears in the document, but is offset by the number of documents
in the corpus that contain the word. Variations of the tf–idf are often used to estimate a document's relevance given a
free-text query.
}
\details{
The reduction of uncertainty...
}
\examples{
\dontrun{
library(data.table)
corpus <- occupations_bundle[language == "en"][ , .(conceptUri, text)]
setnames(corpus, c("id", "text"))
tf_idf(corpus)
}
}
